import requests
from bs4 import BeautifulSoup
from utils import *

url = 'https://pentest-tools.com/jobs'
company = 'PENTESTTOOLS'

r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')

# Get job titles
title_containers = soup.find_all('span', class_='flex items-start justify-between space-x-3 sm:items-center')
job_titles = [container.find('span').text for container in title_containers]

# Get locations
location_containers = soup.find_all('dd', {'data-content-block-body': True})
locations = [(x.split(',')[0].strip(), x.split(',')[1].strip()) for x in [location.text for location in location_containers]]

# Get job links
link_containers = soup.find_all('a', class_='inline-flex cursor-pointer touch-none select-none items-center justify-center whitespace-nowrap border text-center font-semibold tracking-tight transition focus:outline-none disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-75 btn-base btn-tertiary relative -mr-px w-0 flex-1 focus:z-10')
job_links = [link['href'] for link in link_containers]  # Not modifying the links here

final_jobs = []

# Combine data and print
base_url = "https://pentest-tools.com"
for title, location, link in zip(job_titles, locations, job_links):
    city, country = location
    full_link = base_url if link.startswith('/jobs') else url  # conditionally decide which URL to use as the base
    final_jobs.append(
            create_job(
                job_title = title,
                company = company,
                country = location[1],
                city = location[0],
                job_link = full_link + link
            )
    )

for version in [1, 4]:
    publish(version, company, final_jobs, 'Grasum_Key')

publish_logo(company, 'https://pentest-tools.com/images/logos/pentesttools-logomark.svg')

print(json.dumps(final_jobs, indent=4))
